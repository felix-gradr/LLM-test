[
  "Here are three small, high\u2010impact tasks that directly target \u201ccleaning up junk\u201d and \u201ccurating the LLM context window.\u201d  Each one can be implemented in isolation, yet together they will (a) keep your repo tidy, (b) keep your LLM inputs lean, and (c) automatically remove the one\u2010time seed.txt on first run",
  "Task: Auto-remove seed.txt",
  "In your main entrypoint (root.py), detect if `seed.txt` exists and delete it as soon as the run completes (or at startup)",
  "This guarantees that after the first iteration, the seed file vanishes automatically\u2014no more manual cleanup",
  "Task: Filter junk out of `_snapshot_codebase`",
  "Enhance `coder._snapshot_codebase()` to skip not just virtual\u2010env folders, but also:",
  "\u2022 `__pycache__` directories",
  "\u2022 `.pyc`, `.log`, `.tmp`, `.DS_Store` files",
  "\u2022 `.git`, `.svn`, `.hg` folders",
  "That way, every time you snapshot the repo for LLM editing, you\u2019ll only include real code",
  "Task: Truncate LLM context to the last N messages",
  "In your `llm_utils.chat_completion()` (or by wrapping it), add a simple \u201cwindowing\u201d step:",
  "\u2022 If the total token/character count of the `messages` list exceeds a configured threshold, drop the oldest messages until you\u2019re under the limit",
  "\u2022 Expose a `MAX_CONTEXT_TOKENS` (or `MAX_MESSAGES`) constant in a config file so you can tweak it later",
  "Each of these can be handled by a single \u201capply_task(\u2026)\u201d call and will immediately (1) automate seed removal, (2) keep pending code snapshots clean, and (3) ensure your LLM never chokes on an insanely large context window"
]