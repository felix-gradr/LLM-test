[2025-07-18T23:50:34] {
  "action": "modify_files",
  "changes": [
    {
      "path": "root.py",
      "content": "from __future__ import annotations\n\nimport json\nimport os\nfrom dotenv import load_dotenv\nfrom datetime import datetime\nfrom pathlib import Path\n\nfrom openai import AzureOpenAI\n\n# --- NEW ---------------------------------------------------------------\n# Prefer the new structured memory manager but keep legacy log for\n# backward-compatibility & easy grepping.  This staged approach minimises\n# risk while we port existing features.\ntry:\n    from memory_manager import Memory  # type: ignore\nexcept Exception as exc:  # pragma: no cover – should never fail\n    Memory = None  # fallback handled later\n    print(\"[WARN] Failed to import memory_manager –\", exc)\n# ----------------------------------------------------------------------\n\nload_dotenv(override=True)\n\n# File types that the agent is allowed to read/write.  Adjust as needed.\nCODE_EXTENSIONS = {\".py\", \".txt\", \".md\"}\n\n# Legacy flat-text memory file (kept for now).\nMEMORY_PATH = Path(__file__).parent / \"memory.log\"\nMEMORY_CHAR_LIMIT = 4000  # ~ 1k tokens\n\n# Load SYSTEM_PROMPT from prompt.txt\nSYSTEM_PROMPT = (Path(__file__).parent / \"system_prompt.txt\").read_text(encoding=\"utf-8\").strip()\n\n# Load goal from goal.md\nGOAL = (Path(__file__).parent / \"goal.md\").read_text(encoding=\"utf-8\").strip()\n\n\n# ---------------------------------------------------------------------------\n# Helper functions – filesystem & .gitignore handling (unchanged)\n# ---------------------------------------------------------------------------\n\n\ndef _read_gitignore(root: Path) -> list[str]:\n    \"\"\"Read and parse .gitignore rules from the root directory.\"\"\"\n    gitignore = root / \".gitignore\"\n    if not gitignore.is_file():\n        return []\n\n    patterns = []\n    with gitignore.open(\"r\", encoding=\"utf-8\") as f:\n        for line in f:\n            line = line.strip()\n            if line and not line.startswith(\"#\"):\n                patterns.append(line)\n    return patterns\n\n\ndef _is_ignored(path: Path, root: Path, ignore_patterns: list[str]) -> bool:\n    \"\"\"Check if a path is ignored by .gitignore rules.\"\"\"\n    import fnmatch\n    rel_path = str(path.relative_to(root).as_posix())\n    for pattern in ignore_patterns:\n        # Handle directory-only patterns (e.g., \"node_modules/\")\n        if pattern.endswith('/'):\n            # Match if the path starts with the directory pattern\n            if rel_path.startswith(pattern):\n                return True\n            # Also match against the pattern with a wildcard for files inside\n            if fnmatch.fnmatch(rel_path, pattern + '*'):\n                return True\n        # Handle patterns without slashes (e.g., \"*.log\")\n        elif '/' not in pattern:\n            if fnmatch.fnmatch(path.name, pattern):\n                return True\n        # Handle patterns with slashes (e.g., \"config/*.ini\")\n        else:\n            if fnmatch.fnmatch(rel_path, pattern):\n                return True\n    return False\n\n\ndef read_codebase(root: Path) -> dict[str, str]:\n    \"\"\"Return a dict mapping relative paths to file contents, respecting .gitignore.\"\"\"\n    files: dict[str, str] = {}\n    ignore_patterns = _read_gitignore(root)\n    for path in root.rglob(\"*\"):\n        if path.is_dir() or _is_ignored(path, root, ignore_patterns):\n            continue\n        if path.suffix in CODE_EXTENSIONS and path.is_file():\n            try:\n                files[str(path.relative_to(root))] = path.read_text()\n            except UnicodeDecodeError:\n                # Skip binary or non-UTF8 files\n                continue\n    return files\n\n\ndef apply_changes(root: Path, changes: list[dict]):\n    \"\"\"Write files returned by the LLM safely inside *root*.\"\"\"\n    for change in changes:\n        rel_path = change[\"path\"].lstrip(\"/\\\\\")\n        target = root / rel_path\n        target.parent.mkdir(parents=True, exist_ok=True)\n        target.write_text(change[\"content\"], encoding=\"utf-8\")\n        print(f\"[{datetime.utcnow().isoformat(timespec='seconds')}] Wrote {rel_path}\")\n\n\n# ------------------------------  MEMORY  ------------------------------------\n\n\ndef _load_memory(max_chars: int = MEMORY_CHAR_LIMIT) -> str:\n    \"\"\"Return recent memory excerpt for prompt injection (prefers structured).\"\"\"\n    if Memory is not None:\n        try:\n            return Memory.summarise(max_chars=max_chars)\n        except Exception as exc:  # fallback to legacy on error\n            print(\"[WARN] Memory.summarise failed – using legacy log:\", exc)\n\n    # Legacy flat-file fallback\n    if not MEMORY_PATH.is_file():\n        return \"\"\n    text = MEMORY_PATH.read_text(encoding=\"utf-8\")\n    return text[-max_chars:]\n\n\n\ndef _append_memory(snippet: str, entry_type: str = \"observation\") -> None:\n    \"\"\"Append *snippet* to both structured & legacy memory stores.\"\"\"\n    # 1) Structured JSONL (if available)\n    if Memory is not None:\n        try:\n            from typing import cast\n            etype_lit = cast(\"Literal['plan','action','observation','reflection']\", entry_type)\n            Memory.append(etype_lit, snippet)\n        except Exception as exc:\n            print(\"[WARN] Memory.append failed:\", exc)\n\n    # 2) Legacy flat log (kept for easy manual reading)\n    timestamp = datetime.utcnow().isoformat(timespec=\"seconds\")\n    MEMORY_PATH.write_text(f\"[{timestamp}] {snippet}\\n\", encoding=\"utf-8\", errors=\"ignore\") if hasattr(Path, 'write_text') else open(MEMORY_PATH, 'a', encoding='utf-8').write(f\"[{timestamp}] {snippet}\\n\")\n\n\n# ------------------------------  AGENT LOOP  --------------------------------\n\n\ndef agent_step(root: Path, model: str = \"o3-ver1\") -> None:\n    global GOAL\n    \"\"\"Run one reasoning / coding cycle.\"\"\"\n\n    # Gather current snapshot of the code base (truncated)\n    snapshot = read_codebase(root)\n    joined = \"\\n\".join(f\"## {p}\\n{c}\" for p, c in snapshot.items())[:100000]\n    # Retrieve memory excerpt to provide continuity across iterations\n    memory_excerpt = _load_memory()\n\n    user_prompt = (\n        f\"Today is {datetime.utcnow().date()}.\\n\"\n        f\"Your GOAL: {GOAL}\\n\\n\"\n        f\"Here is relevant MEMORY from previous iterations (last {len(memory_excerpt)} chars):\\n{memory_excerpt}\\n\\n\"\n        f\"Here is the current codebase (truncated):\\n{joined}\"\n    )\n\n    client = AzureOpenAI(\n        api_key=os.getenv(\"AZURE_KEY\"),\n        azure_endpoint=os.getenv(\"AZURE_ENDPOINT\"),\n        api_version=\"2025-03-01-preview\",\n    )\n\n    response = client.chat.completions.create(\n        model=model,\n        reasoning_effort=\"high\",\n        messages=[\n            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n            {\"role\": \"user\", \"content\": user_prompt},\n        ],\n    )\n\n    reply = response.choices[0].message.content.strip()\n\n    # Persist raw reply for traceability BEFORE parsing\n    _append_memory(reply, entry_type=\"observation\")\n\n    try:\n        actions = json.loads(reply)\n    except json.JSONDecodeError:\n        print(\"[WARN] LLM returned invalid JSON. Skipping iteration.\")\n        return\n\n    action = actions.get(\"action\")\n    if action in {\"modify_files\", \"create_files\", \"append_files\"}:\n        apply_changes(root, actions.get(\"changes\", []))\n        _append_memory(json.dumps(actions, ensure_ascii=False), entry_type=\"action\")\n    elif action == \"human_help\":\n        print(\"[AGENT] Requests human assistance:\\n\" + actions.get(\"message_to_human\", \"\"))\n    elif action == \"no_op\":\n        print(\"[AGENT] No changes proposed this iteration.\")\n    else:\n        print(f\"[WARN] Unknown action '{action}'. Skipping.\")\n\n    # Delete seed.txt (only relevant for the first run)\n    seed_file = root / \"seed.txt\"\n    if seed_file.exists():\n        seed_file.unlink()\n        print(f\"[{datetime.utcnow().isoformat(timespec='seconds')}] Deleted {seed_file}\")\n\n\ndef main():\n    project_root = Path(__file__).parent.resolve()\n    agent_step(project_root)\n\n\nif __name__ == \"__main__\":\n    main()\n"
    }
  ]
}
